{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Feedback prediction\nkaggle: https://www.kaggle.com/competitions/feedback-prize-effectiveness/overview","metadata":{}},{"cell_type":"markdown","source":"## Import","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import log_loss\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:07.789482Z","iopub.execute_input":"2022-05-31T09:29:07.789881Z","iopub.status.idle":"2022-05-31T09:29:16.476729Z","shell.execute_reply.started":"2022-05-31T09:29:07.789801Z","shell.execute_reply":"2022-05-31T09:29:16.475876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"# train = pd.read_csv('./data/train.csv')\n# test = pd.read_csv('./data/test.csv')\ntrain = pd.read_csv('../input/feedback-prize-effectiveness/train.csv')\ntest = pd.read_csv('../input/feedback-prize-effectiveness/test.csv')\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:16.478439Z","iopub.execute_input":"2022-05-31T09:29:16.47898Z","iopub.status.idle":"2022-05-31T09:29:16.750851Z","shell.execute_reply.started":"2022-05-31T09:29:16.478942Z","shell.execute_reply":"2022-05-31T09:29:16.75001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:16.752209Z","iopub.execute_input":"2022-05-31T09:29:16.752587Z","iopub.status.idle":"2022-05-31T09:29:16.77034Z","shell.execute_reply.started":"2022-05-31T09:29:16.75255Z","shell.execute_reply":"2022-05-31T09:29:16.769594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:16.772718Z","iopub.execute_input":"2022-05-31T09:29:16.773272Z","iopub.status.idle":"2022-05-31T09:29:16.784757Z","shell.execute_reply.started":"2022-05-31T09:29:16.773236Z","shell.execute_reply":"2022-05-31T09:29:16.783764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type_values = train['discourse_type'].value_counts()\ntype_values","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:16.785797Z","iopub.execute_input":"2022-05-31T09:29:16.786528Z","iopub.status.idle":"2022-05-31T09:29:16.80374Z","shell.execute_reply.started":"2022-05-31T09:29:16.786492Z","shell.execute_reply":"2022-05-31T09:29:16.802782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_values = train['discourse_effectiveness'].value_counts()\ntarget_values","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:16.805424Z","iopub.execute_input":"2022-05-31T09:29:16.805883Z","iopub.status.idle":"2022-05-31T09:29:16.819794Z","shell.execute_reply.started":"2022-05-31T09:29:16.805848Z","shell.execute_reply":"2022-05-31T09:29:16.819154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess","metadata":{}},{"cell_type":"code","source":"train_dir = \"../input/feedback-prize-effectiveness/train\"\ntest_dir = \"../input/feedback-prize-effectiveness/test\"\n# train_dir = './data/train'\n# test_dir = './data/test'\ndef get_essay(eassy_id, dir):\n    essay_dir = os.path.join(dir, f'{eassy_id}.txt')\n    essay_txt = open(essay_dir, 'r').read()\n    return essay_txt\n","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:16.821034Z","iopub.execute_input":"2022-05-31T09:29:16.821587Z","iopub.status.idle":"2022-05-31T09:29:16.82703Z","shell.execute_reply.started":"2022-05-31T09:29:16.821554Z","shell.execute_reply":"2022-05-31T09:29:16.826345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['essay_text'] = train['essay_id'].apply(lambda x: get_essay(x, train_dir))\ntest['essay_text'] = test['essay_id'].apply(lambda x: get_essay(x, test_dir))\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:16.829522Z","iopub.execute_input":"2022-05-31T09:29:16.830511Z","iopub.status.idle":"2022-05-31T09:29:48.399802Z","shell.execute_reply.started":"2022-05-31T09:29:16.830485Z","shell.execute_reply":"2022-05-31T09:29:48.398972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain['discourse_effectiveness'] = encoder.fit_transform(train['discourse_effectiveness'])","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:48.402665Z","iopub.execute_input":"2022-05-31T09:29:48.403426Z","iopub.status.idle":"2022-05-31T09:29:48.419905Z","shell.execute_reply.started":"2022-05-31T09:29:48.403383Z","shell.execute_reply":"2022-05-31T09:29:48.419212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:48.424224Z","iopub.execute_input":"2022-05-31T09:29:48.424472Z","iopub.status.idle":"2022-05-31T09:29:48.437673Z","shell.execute_reply.started":"2022-05-31T09:29:48.424449Z","shell.execute_reply":"2022-05-31T09:29:48.436781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class EssayDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=512):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.discourse = df['discourse_text'].values\n        self.essay = df['essay_text'].values\n        if 'discourse_effectiveness' in self.df:\n            self.target = df['discourse_effectiveness'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        discourse = self.discourse[idx]\n        essay = self.essay[idx]\n        text = discourse + \" \" + self.tokenizer.sep_token + \" \" + essay\n\n        encode_dict = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            truncation=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        ids = encode_dict['input_ids']\n        mask = encode_dict['attention_mask']\n\n        ids = ids.squeeze(0)\n        mask = mask.squeeze(0)\n\n        if 'discourse_effectiveness' in self.df:\n            target = self.target[idx]\n            return {\"ids\" : ids, \"mask\": mask, \"target\": target}\n        return {\"ids\": ids, \"mask\": mask}","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:48.439195Z","iopub.execute_input":"2022-05-31T09:29:48.439596Z","iopub.status.idle":"2022-05-31T09:29:48.450021Z","shell.execute_reply.started":"2022-05-31T09:29:48.439562Z","shell.execute_reply":"2022-05-31T09:29:48.449155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = '../input/deberta-v3-base/deberta-v3-base'","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:48.451188Z","iopub.execute_input":"2022-05-31T09:29:48.451627Z","iopub.status.idle":"2022-05-31T09:29:48.462606Z","shell.execute_reply.started":"2022-05-31T09:29:48.451591Z","shell.execute_reply":"2022-05-31T09:29:48.461803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:48.463744Z","iopub.execute_input":"2022-05-31T09:29:48.464037Z","iopub.status.idle":"2022-05-31T09:29:49.166716Z","shell.execute_reply.started":"2022-05-31T09:29:48.464001Z","shell.execute_reply":"2022-05-31T09:29:49.165963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = 512\ntrain_, valid_ = train_test_split(train, test_size=0.2, random_state=42)\ntrain_dataset = EssayDataset(train_, tokenizer, max_len)\n# train_dataset = EssayDataset(train, tokenizer, max_len)\nvalid_dataset = EssayDataset(valid_, tokenizer, max_len)\ntest_dataset = EssayDataset(test, tokenizer, max_len)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:49.168003Z","iopub.execute_input":"2022-05-31T09:29:49.168958Z","iopub.status.idle":"2022-05-31T09:29:49.190324Z","shell.execute_reply.started":"2022-05-31T09:29:49.168911Z","shell.execute_reply":"2022-05-31T09:29:49.189561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"# loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n# for batch in loader:\n#     print(batch['ids'].shape, batch['mask'].shape, batch['target'].shape)\n#     print(batch['target'])\n#     model = AutoModelForSequenceClassification.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\", num_labels=3, output_attentions=False, output_hidden_states=False)\n#     loss, logits = model(batch['ids'], attention_mask=batch['mask'], labels=batch['target'], return_dict=False)\n#     print(loss)\n#     print(logits)\n#     break","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:29:49.191531Z","iopub.execute_input":"2022-05-31T09:29:49.192323Z","iopub.status.idle":"2022-05-31T09:29:49.196736Z","shell.execute_reply.started":"2022-05-31T09:29:49.192287Z","shell.execute_reply":"2022-05-31T09:29:49.195798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classifier(pl.LightningModule):\n    def __init__(self, hparams):\n        super(Classifier, self).__init__()\n        \n        self.model = AutoModelForSequenceClassification.from_pretrained(hparams['model_name'], config=hparams['model_config'])\n        \n        self.batch_size = hparams[\"batch_size\"]\n        self.lr = hparams[\"lr\"]\n        self.gamma = hparams['gamma']\n        self.wd = hparams['weight_decay']\n        self.steps = hparams['total_steps']\n\n    def forward(self, batch):\n        if len(batch) == 3:\n            input_ids, attention_masks, labels = batch['ids'], batch['mask'], batch['target']\n            loss, logits = self.model(input_ids, attention_mask=attention_masks, labels=labels, token_type_ids=None, return_dict=False)\n            return loss, logits\n        else:\n            input_ids, attention_mask = batch['ids'], batch['mask']\n            logits = self.model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n            return logits[0]\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=self.wd)\n#     IF using scheduler with warmup,\n#     after experiments, found the loss remains in 1.1, not converge. \n#         scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=self.steps)\n#         scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=self.steps)\n#         scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, self.gamma)\n#         return [optimizer], [scheduler]\n        return optimizer\n\n    def training_step(self, batch, batch_idx):\n        loss, logits = self.forward(batch)\n        \n        pred_flat = torch.argmax(logits, dim=1).flatten()\n        labels_flat = batch['target'].flatten()\n        acc = torch.sum(pred_flat == labels_flat) / len(labels_flat)\n        self.log(\"train_loss\", loss, on_epoch=True, on_step=False)\n        self.log(\"train_acc\", acc, on_epoch=True, on_step=False)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        loss, logits = self.forward(batch)\n        pred_flat = torch.argmax(logits, dim=1).flatten()\n        labels_flat = batch['target'].flatten()\n        acc = torch.sum(pred_flat == labels_flat) / len(labels_flat)\n        self.log(\"val_loss\", loss)\n        self.log(\"val_acc\", acc)\n\n    def train_dataloader(self):\n        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n        return train_loader\n\n    def val_dataloader(self):\n        valid_loader = DataLoader(valid_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n        return valid_loader\n\n    def test_dataloader(self):\n        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n        return test_loader","metadata":{"id":"U4K6-Y661BfG","execution":{"iopub.status.busy":"2022-05-31T09:32:45.481179Z","iopub.execute_input":"2022-05-31T09:32:45.481741Z","iopub.status.idle":"2022-05-31T09:32:45.499049Z","shell.execute_reply.started":"2022-05-31T09:32:45.481703Z","shell.execute_reply":"2022-05-31T09:32:45.498168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"pl.seed_everything(42)\nhparams = {\n    \"batch_size\": 16,\n    \"lr\": 2e-5,\n    \"gamma\": 0.8,\n    \"weight_decay\": 1e-2,\n    \"model_name\": model_name,\n    \"epochs\": 3,\n}\nloader = DataLoader(train_dataset, batch_size=hparams[\"batch_size\"])\nhparams[\"total_steps\"] = len(loader) * hparams[\"epochs\"]\n\nmodel_config = AutoConfig.from_pretrained(hparams[\"model_name\"], num_labels=3, output_attentions=False, output_hidden_states=False)\nmodel_config.hidden_dropout_prob = 0.2\nhparams[\"model_config\"] = model_config","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:32:47.981418Z","iopub.execute_input":"2022-05-31T09:32:47.982246Z","iopub.status.idle":"2022-05-31T09:32:47.994703Z","shell.execute_reply.started":"2022-05-31T09:32:47.982207Z","shell.execute_reply":"2022-05-31T09:32:47.993941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lightning = Classifier(hparams)\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor=\"val_acc\",\n    dirpath=\"./ckpts/\",\n    mode='max',\n    filename='best.pth',\n)\ntrainer = pl.Trainer(\n    gpus=1, \n    max_epochs=hparams[\"epochs\"], \n    precision=16, \n    gradient_clip_val=1.0, \n    val_check_interval=0.5,\n    callbacks=[checkpoint_callback]\n)","metadata":{"id":"zCJx2w0w1BfG","outputId":"2c5d9567-5474-446a-db1d-574bcaab9b53","execution":{"iopub.status.busy":"2022-05-31T09:32:50.734613Z","iopub.execute_input":"2022-05-31T09:32:50.735546Z","iopub.status.idle":"2022-05-31T09:32:52.833052Z","shell.execute_reply.started":"2022-05-31T09:32:50.735496Z","shell.execute_reply":"2022-05-31T09:32:52.832236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(lightning)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T09:32:56.624615Z","iopub.execute_input":"2022-05-31T09:32:56.624971Z","iopub.status.idle":"2022-05-31T09:33:46.385126Z","shell.execute_reply.started":"2022-05-31T09:32:56.624937Z","shell.execute_reply":"2022-05-31T09:33:46.38313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"predictions = trainer.predict(dataloaders=lightning.test_dataloader(), ckpt_path='best')","metadata":{"id":"COWHXsc_WcIc","outputId":"8385c095-12fa-4ffd-fc80-a858efaa626b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nfor batch in predictions:\n  preds.append(batch)\n\npreds = torch.concat(preds)\npreds = preds.type(torch.float32)\npreds = F.softmax(preds, dim=1)\n# preds.shape\nsample = pd.read_csv(\"../input/feedback-prize-effectiveness/sample_submission.csv\")\nsample['Adequate'] = preds[:, 0]\nsample['Effective'] = preds[:, 1]\nsample['Ineffective'] = preds[:, 2]\nprint(sample.head())\nsample.to_csv(\"submission.csv\", index=False)","metadata":{"id":"7OkUkXsuYgi0","trusted":true},"execution_count":null,"outputs":[]}]}
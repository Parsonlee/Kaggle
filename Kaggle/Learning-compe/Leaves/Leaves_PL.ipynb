{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 树叶图像分类\n",
    "\n",
    "Kaggle: https://www.kaggle.com/c/classify-leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整理数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/0.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/1.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/2.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/3.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/4.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          image             label\n",
       "0  images/0.jpg  maclura_pomifera\n",
       "1  images/1.jpg  maclura_pomifera\n",
       "2  images/2.jpg  maclura_pomifera\n",
       "3  images/3.jpg  maclura_pomifera\n",
       "4  images/4.jpg  maclura_pomifera"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./Leaves/data/train.csv')\n",
    "test = pd.read_csv('./Leaves/data/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abies_concolor',\n",
       " 'abies_nordmanniana',\n",
       " 'acer_campestre',\n",
       " 'acer_ginnala',\n",
       " 'acer_griseum',\n",
       " 'acer_negundo',\n",
       " 'acer_palmatum',\n",
       " 'acer_pensylvanicum',\n",
       " 'acer_platanoides',\n",
       " 'acer_pseudoplatanus']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对label进行排序\n",
    "labels = sorted(list(set(train['label'])))\n",
    "n_classes = len(labels)\n",
    "print(n_classes)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把label转换成数字\n",
    "class2num = dict(zip(labels, range(n_classes)))\n",
    "# 把数字转回label\n",
    "num2class = dict(zip(range(n_classes), labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建自己的训练集Dataset\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, csv_path, file_path, transform=None):\n",
    "        self.file_path = file_path\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.transform = transform\n",
    "\n",
    "        # 读取csv\n",
    "        self.info = pd.read_csv(csv_path, header=None)\n",
    "        # 第一列包含图像文件名称，第二列是label\n",
    "        self.image_arr = np.asarray(self.info.iloc[1:, 0])  # 读取第一列，从第二行开始\n",
    "        self.label_arr = np.asarray(self.info.iloc[1:, 1])\n",
    "        # 计算length\n",
    "        self.length = len(self.info.index) - 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_image_name = self.image_arr[index]\n",
    "        # 读取图像\n",
    "        img = Image.open(os.path.join(self.file_path, single_image_name))\n",
    "        # 图像增强\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        img = transform(img)\n",
    "        # 读取label\n",
    "        label = self.label_arr[index]\n",
    "        num_label = class2num[label]\n",
    "        return (img, num_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建自己的测试集Dataset\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, csv_path, file_path, transform=None):\n",
    "        self.file_path = file_path\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.transform = transform\n",
    "\n",
    "        # 读取csv\n",
    "        self.info = pd.read_csv(csv_path, header=None)\n",
    "        # 第一列包含图像文件名称，第二列是label\n",
    "        self.image_arr = np.asarray(self.info.iloc[1:, 0])  # 读取第一列，从第二行开始\n",
    "        # 计算长度\n",
    "        self.length = len(self.info.index) - 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_image_name = self.image_arr[index]\n",
    "        # 读取图像\n",
    "        img = Image.open(os.path.join(self.file_path, single_image_name))\n",
    "        # 图像增强\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        img = transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      0                        1\n",
      "0                 image                    label\n",
      "1          images/0.jpg         maclura_pomifera\n",
      "2          images/1.jpg         maclura_pomifera\n",
      "3          images/2.jpg         maclura_pomifera\n",
      "4          images/3.jpg         maclura_pomifera\n",
      "...                 ...                      ...\n",
      "18349  images/18348.jpg          aesculus_glabra\n",
      "18350  images/18349.jpg  liquidambar_styraciflua\n",
      "18351  images/18350.jpg            cedrus_libani\n",
      "18352  images/18351.jpg      prunus_pensylvanica\n",
      "18353  images/18352.jpg          quercus_montana\n",
      "\n",
      "[18354 rows x 2 columns]\n",
      "                     0\n",
      "0                image\n",
      "1     images/18353.jpg\n",
      "2     images/18354.jpg\n",
      "3     images/18355.jpg\n",
      "4     images/18356.jpg\n",
      "...                ...\n",
      "8796  images/27148.jpg\n",
      "8797  images/27149.jpg\n",
      "8798  images/27150.jpg\n",
      "8799  images/27151.jpg\n",
      "8800  images/27152.jpg\n",
      "\n",
      "[8801 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "train_path = './Leaves/data/train.csv'\n",
    "test_path = './Leaves/data/test.csv'\n",
    "# csv文件中已经包含image的路径，因此这里只到上一级目录\n",
    "img_path = './Leaves/data/'\n",
    "\n",
    "train_set = TrainDataset(train_path, img_path)\n",
    "test_set = TestDataset(test_path, img_path)\n",
    "print(train_set.info)\n",
    "print(test_set.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.params = hparams\n",
    "        self.num_classes = self.params['num_classes']\n",
    "        self.lr = self.params['lr']\n",
    "        self.batch_size = self.params['batch_size']\n",
    "        self.weight_decay = self.params['weight_decay']\n",
    "\n",
    "        # /*-------------- model_ResNet18 ----------------*/\n",
    "        self.arch = torchvision.models.resnet50(pretrained=True)\n",
    "        num_ftrs = self.arch.fc.in_features\n",
    "        self.arch.fc = nn.Linear(num_ftrs, self.num_classes)\n",
    "        # /*-------------- model_ResNet18 ----------------*/\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.arch(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        \n",
    "        _, pred = torch.max(y_hat, dim=1)\n",
    "        acc = torch.sum(pred == y.data) / (y.shape[0] * 1.0)\n",
    "        return {'loss': loss, 'train_acc': acc}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['train_acc'] for x in outputs]).mean()\n",
    "        self.log('step', self.trainer.current_epoch)\n",
    "        self.log('avg_loss', avg_loss)\n",
    "        self.log('avg_acc', avg_acc)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(train_set, batch_size=self.batch_size, shuffle=True)\n",
    "        return train_loader\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(test_set, batch_size=self.batch_size, shuffle=False)\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | arch | ResNet | 23.9 M\n",
      "--------------------------------\n",
      "23.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.9 M    Total params\n",
      "95.475    Total estimated model params size (MB)\n",
      "c:\\users\\69570\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:110: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d450354723542fcb434e16768de7e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\69570\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:685: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "hparams = {'num_classes': n_classes, 'lr': 1e-4, 'batch_size': 32, 'weight_decay': 1e-3}\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = Classifier(hparams)\n",
    "# trainer = pl.Trainer(max_epochs=5)\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=30)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\users\\69570\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:110: UserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789986077696461f993f5cedba882fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 288it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 返回长度为batch数的list，每个元素是包含batch_size个样本的tensor\n",
    "predictions = trainer.predict(model, model.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for batch in predictions:\n",
    "    preds.extend(batch.argmax(dim=-1).numpy())\n",
    "\n",
    "# 得到最终预测结果\n",
    "classes = [num2class[i] for i in preds]\n",
    "len(classes)\n",
    "\n",
    "test_data = pd.read_csv(test_path)\n",
    "test_data['label'] = pd.Series(classes)\n",
    "submission = pd.concat([test_data['image'], test_data['label']], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
